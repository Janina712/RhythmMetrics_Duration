{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlUXHb0Zzp7Lxu/vwVbnCs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Janina712/RhythmMetrics_Duration/blob/main/3_2_Match_Groups.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **0. Imports & Set-Up**"
      ],
      "metadata": {
        "id": "3plVZarfgS6g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dAOCZbMgDbz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import random as random\n",
        "import os\n",
        "import math\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "id": "iDmZfi1Agf1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91b16538-d38d-4667-b36a-d4315ac7b954"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/ATAS_Plus/Duration_Metrics/2.BreathGroups_Assigned/"
      ],
      "metadata": {
        "id": "n1zFgsXmgkus",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a76da37d-a0e9-4b58-d35f-713ab6138ea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/ATAS_Plus/Duration_Metrics/2.BreathGroups_Assigned\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reading = pd.read_excel(\"reading_TextGrid_comb_BG_loop.xlsx\")\n",
        "frog = pd.read_excel(\"frog_TextGrid_comb_BG_loop.xlsx\")"
      ],
      "metadata": {
        "id": "qan_HdMTgpUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IDs by condition\n",
        "IDs_reading = ['24fa']\n",
        "IDs_frog = ['24fa']"
      ],
      "metadata": {
        "id": "bi79wlP4gy9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IDs by group\n",
        "IDs_pws = ['24fa']\n",
        "control_IDs = []\n",
        "\n",
        "# combine both groups\n",
        "IDs_col = pd.DataFrame(columns =['ID'])\n",
        "IDs_col['ID'] =['24fa']"
      ],
      "metadata": {
        "id": "siL3cCAohIp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Define Functions**"
      ],
      "metadata": {
        "id": "DH1p5PO-hSnC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.1 Assign Participant Group**"
      ],
      "metadata": {
        "id": "54B9vzDehYcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assign_group(df):\n",
        "  group = pd.DataFrame(index = range(len(df)),columns=[\"Group\"])\n",
        "\n",
        "  for i in range(0,len(df)):\n",
        "    if \"_\" in df[\"ID\"][i]:\n",
        "      group[\"Group\"][i] = \"Control\"\n",
        "    else:\n",
        "      group[\"Group\"][i] = \"PWS\"\n",
        "\n",
        "  df_out = pd.concat([ group, df], axis=1)\n",
        "  df_out = df_out[df_out.Type != \"silence\"]\n",
        "  df_out.index = range(len(df_out.index))\n",
        "  df_out.drop(['Unnamed: 0'], axis=1 , inplace = True)\n",
        "  return(df_out)"
      ],
      "metadata": {
        "id": "FRgqlgA4hRuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.2 Count Vowels**"
      ],
      "metadata": {
        "id": "GU3CIpNphfAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_vowels(df, condition):\n",
        "  df_vowels = df[df[\"Type\"]  == \"vowel\"]\n",
        "  df_vowels.index = range(len(df_vowels.index))\n",
        "\n",
        "  # reading or interview condition\n",
        "  if condition == \"frog\":\n",
        "    IDs_here = IDs_frog\n",
        "  else:\n",
        "    IDs_here = IDs_reading\n",
        "\n",
        "  syll_col = pd.DataFrame()  ## initialize group-level dataframe\n",
        "  for ID in IDs_here: ## loop over participnts\n",
        "    syll_current_ID = pd.DataFrame()   ## initialize participant-level dataframe\n",
        "    subset_sounds = df[df[\"ID\"] == ID]  # get subset of sound dataframe that corresponds to current participant\n",
        "    subset_sounds.index = range(len(subset_sounds.index)) # reset index\n",
        "    subset_vowels = subset_sounds[subset_sounds[\"Type\"] == \"vowel\"]  # get subset of sound dataframe that corresponds to current participant\n",
        "    subset_vowels.index = range(len(subset_vowels.index)) # reset index\n",
        "    syll = subset_vowels[\"Breath.Group\"].value_counts().sort_index() # count how often a certain Breath group occurs for this participant\n",
        "    syll.index = range(len(syll.index)) # reset index\n",
        "    for a in range (0,len(syll)): # go through all breath groups that this participant produced\n",
        "      syll_current_BG = pd.DataFrame()  ## initialize BG-level dataframe\n",
        "      syll_current_BG = pd.DataFrame(np.repeat(syll.iloc[a], syll.iloc[a], axis=0)) #replicate the sum sum times\n",
        "      syll_current_ID = syll_current_ID.append([syll_current_BG], ignore_index = True) # add BG-level dataframe to participant-level dataframe\n",
        "    syll_col = syll_col.append([syll_current_ID], ignore_index = True) # add participant-level dataframe to group-level dataframe\n",
        "\n",
        "  df_vowels = pd.concat([df_vowels, syll_col], axis=1)\n",
        "  df_vowels.rename(columns = {'Syllables':'Unmached_Vowels'}, inplace = True)\n",
        "  df_vowels.rename(columns = {0:'Syllables'}, inplace = True) # rename new column\n",
        "  pre_df_vowel_avg = df_vowels.groupby(\"Group\").mean()    ########### average counting 13 13 times\n",
        "\n",
        "  return(df_vowels, pre_df_vowel_avg)"
      ],
      "metadata": {
        "id": "dS3DHhwthegs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.3 Count Consonants**"
      ],
      "metadata": {
        "id": "hiEuOpEohrdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_consonants(df, condition):\n",
        "  df_consonants = df[df[\"Type\"]  == \"consonant\"]\n",
        "  df_consonants.index = range(len(df_consonants.index))\n",
        "\n",
        "  # reading or interview condition\n",
        "  if condition == \"frog\":\n",
        "    IDs_here = IDs_frog\n",
        "  else:\n",
        "    IDs_here = IDs_reading\n",
        "\n",
        "  con_col = pd.DataFrame()  ## initialize group-level dataframe\n",
        "  for ID in IDs_here: ## loop over participnts\n",
        "    con_current_ID = pd.DataFrame()   ## initialize participant-level dataframe\n",
        "    subset_sounds = df[df[\"ID\"] == ID]  # get subset of sound dataframe that corresponds to current participant\n",
        "    subset_sounds.index = range(len(subset_sounds.index)) # reset index\n",
        "    subset_cons = subset_sounds[subset_sounds[\"Type\"] == \"consonant\"]  # get subset of sound dataframe that corresponds to current participant\n",
        "    subset_cons.index = range(len(subset_cons.index)) # reset index\n",
        "    con = subset_cons[\"Breath.Group\"].value_counts().sort_index() # count how often a certain Breath group occurs for this participant\n",
        "    con.index = range(len(con.index)) # reset index\n",
        "    for a in range (0,len(con)): # go through all breath groups that this participant produced\n",
        "      con_current_BG = pd.DataFrame()  ## initialize BG-level dataframe\n",
        "      con_current_BG = pd.DataFrame(np.repeat(con.iloc[a], con.iloc[a], axis=0)) #replicate the sum sum times\n",
        "      con_current_ID = con_current_ID.append([con_current_BG], ignore_index = True) # add BG-level dataframe to participant-level dataframe\n",
        "    con_col = con_col.append([con_current_ID], ignore_index = True) # add participant-level dataframe to group-level dataframe\n",
        "\n",
        "  df_consonants = pd.concat([df_consonants, con_col], axis=1)\n",
        "  df_consonants.rename(columns = {'Consonants':'Unmatched_Cons'}, inplace = True)\n",
        "  df_consonants.rename(columns = {0:'Consonants'}, inplace = True) # rename new column\n",
        "  pre_df_consonant_avg = df_consonants.groupby(\"Group\").mean()    ########### average counting 13 13 times\n",
        "\n",
        "  return(df_consonants, pre_df_consonant_avg)"
      ],
      "metadata": {
        "id": "eW12HxyShedJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.4 Average Vowel Count Per Participant**"
      ],
      "metadata": {
        "id": "P5xRWEFwh1ml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def participant_vowel_avg(df, condition):\n",
        "  if condition == \"frog\":\n",
        "    IDs_here = IDs_frog\n",
        "  else:\n",
        "    IDs_here = IDs_reading\n",
        "\n",
        "  n = -1\n",
        "  avg_col = pd.DataFrame(index = range(len(IDs_col)),columns=[\"Syllables\"])   # Syllables\n",
        "  for ID in IDs_here: ## loop over participnts\n",
        "    n = n + 1\n",
        "    subset_BGs = df[df[\"ID\"] == ID]  # get subset of sound dataframe that corresponds to current participant\n",
        "    subset_BGs.index = range(len(subset_BGs.index)) # reset index\n",
        "    BG_avg = subset_BGs.groupby(\"Breath.Group\").mean()\n",
        "    subj_avg = BG_avg[\"Syllables\"].mean()\n",
        "    avg_col[\"Syllables\"][n] = subj_avg\n",
        "\n",
        "    group_col = pd.DataFrame(columns=['Group'])\n",
        "    IDs_col_here = pd.DataFrame(columns=['ID'])\n",
        "    group_list = []\n",
        "    for i in range(0,len(IDs_here)):\n",
        "      if \"_\" in IDs_here[i]: #\"ID\"\n",
        "        group_list.append(\"Control\")\n",
        "      else:\n",
        "        group_list.append('PWS')\n",
        "\n",
        "    group_col[\"Group\"] = group_list\n",
        "    IDs_col_here[\"ID\"] = IDs_here\n",
        "\n",
        "  df_participant_vowel_avg = pd.concat([group_col, IDs_col_here, avg_col], axis=1)\n",
        "\n",
        "  return(df_participant_vowel_avg)"
      ],
      "metadata": {
        "id": "kffQx9pxheat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.5 Average Consonant Count Per Participant**"
      ],
      "metadata": {
        "id": "ha6VnHdGiCbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def participant_consonant_avg(df, condition):\n",
        "  if condition == \"frog\":\n",
        "    IDs_here = IDs_frog\n",
        "  else:\n",
        "    IDs_here = IDs_reading\n",
        "\n",
        "  n = -1\n",
        "  avg_col = pd.DataFrame(index = range(len(IDs_col)),columns=[\"Consonants\"])\n",
        "  for ID in IDs_here: ## loop over participnts\n",
        "    n = n + 1\n",
        "    subset_BGs = df[df[\"ID\"] == ID]  # get subset of sound dataframe that corresponds to current participant\n",
        "    subset_BGs.index = range(len(subset_BGs.index)) # reset index\n",
        "    BG_avg = subset_BGs.groupby(\"Breath.Group\").mean()\n",
        "    subj_avg = BG_avg[\"Consonants\"].mean()\n",
        "    avg_col[\"Consonants\"][n] = subj_avg\n",
        "\n",
        "    group_col = pd.DataFrame(columns=['Group'])\n",
        "    IDs_col_here = pd.DataFrame(columns=['ID'])\n",
        "    group_list = []\n",
        "    for i in range(0,len(IDs_here)):\n",
        "      if \"_\" in IDs_here[i]: #\"ID\"\n",
        "        group_list.append(\"Control\")\n",
        "      else:\n",
        "        group_list.append('PWS')\n",
        "\n",
        "    group_col[\"Group\"] = group_list\n",
        "    IDs_col_here[\"ID\"] = IDs_here\n",
        "\n",
        "  df_participant_cons_avg = pd.concat([group_col, IDs_col, avg_col], axis=1)\n",
        "\n",
        "  return(df_participant_cons_avg)"
      ],
      "metadata": {
        "id": "fBzkv5x5heXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.6 Compare Consonant and Vowel Counts Across Groups**"
      ],
      "metadata": {
        "id": "96RqZRcJiZ1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_groups(df_vowels, df_consonants):\n",
        "  if df_vowels[\"Group\"][0] == \"PWS\":\n",
        "    first_IDs = IDs_pws\n",
        "    first = \"PWS\"\n",
        "    second_IDs = control_IDs\n",
        "    second = \"Control\"\n",
        "  else:\n",
        "    first_IDs = control_IDs\n",
        "    first = \"Control\"\n",
        "    second_IDs = IDs_pws\n",
        "    second = \"PWS\"\n",
        "\n",
        "  second_v = (df_vowels.groupby('ID').mean()[\"Syllables\"][len(first_IDs):(len(first_IDs) + len(control_IDs))]).mean()\n",
        "  first_v = (df_vowels.groupby('ID').mean()[\"Syllables\"][0:len(first_IDs)]).mean()\n",
        "  difference_v = abs(second_v - first_v)\n",
        "\n",
        "  second_c = (df_consonants.groupby(\"ID\").mean()[\"Consonants\"][len(first_IDs):(len(first_IDs)+len(control_IDs))]).mean()\n",
        "  first_c = (df_consonants.groupby('ID').mean()[\"Consonants\"][0:len(first_IDs)]).mean()\n",
        "  difference_c = abs(second_c - first_c)\n",
        "\n",
        "  if first_v > second_v:\n",
        "    longer = first\n",
        "    shorter = second\n",
        "    short_v = second_v\n",
        "    short_c = second_c\n",
        "  elif second_v > first_v:\n",
        "    longer = second\n",
        "    shorter = first\n",
        "    short_v = first_v\n",
        "    short_c = first_c\n",
        "  elif (np.isnan(first_v)):\n",
        "    longer = second\n",
        "    shorter = first\n",
        "    short_v = first_v\n",
        "    short_c = first_c\n",
        "  else:\n",
        "    longer = first\n",
        "    shorter = second\n",
        "    short_v = second_v\n",
        "    short_c = second_c\n",
        "\n",
        "  string1 = (f\"{first} produced on average {round(first_v,2)} syllables per utterance, while {second} participants produced {round(second_v,2)} syllables on average.\")\n",
        "  string2 = (f\"This means that there is a difference of {round(difference_v,2)} syllables per utterance.\")\n",
        "  string3 = (f\"\\n{first} produced on average {round(first_c,2)} consonants per utterance, while {second} participants produced {round(second_c,2)} consonants on average.\")\n",
        "  string4 = (f\"This means that there is a difference of {round(difference_c,2)} consonants per utterance.\")\n",
        "  string5 =(f\"\\n{longer} participants produced longer utterances than {shorter} on the frog condition.\")\n",
        "\n",
        "  return(string1, string2, string3, string4, string5, short_v, short_c, difference_v, difference_c, longer, shorter)"
      ],
      "metadata": {
        "id": "aeEb4YhKheFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.7 Match Number of Vowels Across Groups**"
      ],
      "metadata": {
        "id": "H0P231W_igGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def match_vowels(df_vowels, short_group, cut_v, condition):\n",
        "  if condition == 'frog':\n",
        "    IDs_here = IDs_frog\n",
        "  else:\n",
        "    IDs_here = IDs_reading\n",
        "\n",
        "  groups = []\n",
        "  for person in IDs_here:\n",
        "    if person in IDs_pws:\n",
        "      groups.append(\"PWS\")\n",
        "    if person in control_IDs:\n",
        "      groups.append(\"Control\")\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "  if len(groups) < 2:\n",
        "    print(f\"Only one group for {condition} condition. Matching not possible.\")\n",
        "    syll_col_matched = df_vowels\n",
        "  else:\n",
        "    cut_v = round(cut_v)\n",
        "    syll_col_matched = pd.DataFrame()  ## initialize group-level dataframe\n",
        "    participant = pd.DataFrame()  ## initialize participant-level dataframe\n",
        "    if short_group == \"PWS\":\n",
        "      df_control = df_vowels[df_vowels[\"Group\"]  == \"Control\"]\n",
        "      df_control.index = range(len(df_control.index)) ## group\n",
        "      for ID in control_IDs:\n",
        "        df_control_ID = df_control[df_control[\"ID\"]  == ID]\n",
        "        df_control_ID.index = range(len(df_control_ID.index))  ### person\n",
        "        BGs = df_control_ID[\"Breath.Group\"].unique()\n",
        "        for BG in BGs:\n",
        "          df_control_ID_BG = df_control_ID[df_control_ID[\"Breath.Group\"]  == BG]\n",
        "          df_control_ID_BG.index = range(len(df_control_ID_BG.index)) ## BG\n",
        "          if len(df_control_ID_BG) >= cut_v:\n",
        "            df_control_ID_BG.drop(df_control_ID_BG.tail(cut_v).index, inplace = True)\n",
        "            participant = participant.append([df_control_ID_BG], ignore_index = True)\n",
        "          else:\n",
        "            participant = participant.append([df_control_ID_BG], ignore_index = True)\n",
        "    else:\n",
        "        df_control = df_vowels[df_vowels[\"Group\"]  == \"PWS\"]\n",
        "        df_control.index = range(len(df_control.index)) ## group\n",
        "        for ID in IDs_pws:\n",
        "          df_control_ID = df_control[df_control[\"ID\"]  == ID]\n",
        "          df_control_ID.index = range(len(df_control_ID.index))  ### person\n",
        "          BGs = df_control_ID[\"Breath.Group\"].unique()\n",
        "          for BG in BGs:\n",
        "            df_control_ID_BG = df_control_ID[df_control_ID[\"Breath.Group\"]  == BG]\n",
        "            df_control_ID_BG.index = range(len(df_control_ID_BG.index)) ## BG\n",
        "            if len(df_control_ID_BG) >= cut_v:\n",
        "              df_control_ID_BG.drop(df_control_ID_BG.tail(cut_v).index, inplace = True)\n",
        "              participant = participant.append([df_control_ID_BG], ignore_index = True)\n",
        "            else:\n",
        "              participant = participant.append([df_control_ID_BG], ignore_index = True)\n",
        "        syll_col_matched = syll_col_matched.append([participant], ignore_index = True) # add participant-level dataframe to group-level dataframe\n",
        "  return(syll_col_matched)"
      ],
      "metadata": {
        "id": "SXV94KYaisr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.8 Match Number of Consonants Across Groups**"
      ],
      "metadata": {
        "id": "PnbTZfyZi8Nk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def match_consonants(df_consonants, short_group, cut_c, condition):\n",
        "  if condition == 'frog':\n",
        "    IDs_here = IDs_frog\n",
        "  else:\n",
        "    IDs_here = IDs_reading\n",
        "\n",
        "  groups = []\n",
        "  for person in IDs_here:\n",
        "    if person in IDs_pws:\n",
        "      groups.append(\"PWS\")\n",
        "    if person in control_IDs:\n",
        "      groups.append(\"Control\")\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "  if len(groups) < 2:\n",
        "    print(f\"Only one group for {condition} condition. Matching not possible.\")\n",
        "    cons_col_matched = df_consonants\n",
        "  else:\n",
        "    cut_c = round(cut_c)\n",
        "    cons_col_matched = pd.DataFrame()  ## initialize group-level dataframe\n",
        "    participant = pd.DataFrame()  ## initialize participant-level dataframe\n",
        "    if short_group == \"PWS\":\n",
        "      df_control = df_consonants[df_consonants[\"Group\"]  == \"Control\"]\n",
        "      df_control.index = range(len(df_control.index)) ## group\n",
        "      for ID in control_IDs:\n",
        "        df_control_ID = df_control[df_control[\"ID\"]  == ID]\n",
        "        df_control_ID.index = range(len(df_control_ID.index))  ### person\n",
        "        BGs = df_control_ID[\"Breath.Group\"].unique()\n",
        "        for BG in BGs:\n",
        "          df_control_ID_BG = df_control_ID[df_control_ID[\"Breath.Group\"]  == BG]\n",
        "          df_control_ID_BG.index = range(len(df_control_ID_BG.index)) ## BG\n",
        "          if len(df_control_ID_BG) >= cut_c:\n",
        "            df_control_ID_BG.drop(df_control_ID_BG.tail(cut_c).index, inplace = True)\n",
        "            participant = participant.append([df_control_ID_BG], ignore_index = True)\n",
        "          else:\n",
        "            participant = participant.append([df_control_ID_BG], ignore_index = True)\n",
        "        cons_col_matched = cons_col_matched.append([participant], ignore_index = True) # add participant-level dataframe to group-level dataframe\n",
        "    else:\n",
        "      df_control = df_consonants[df_consonants[\"Group\"]  == \"PWS\"]\n",
        "      df_control.index = range(len(df_control.index)) ## group\n",
        "      for ID in IDs_pws:\n",
        "        df_control_ID = df_control[df_control[\"ID\"]  == ID]\n",
        "        df_control_ID.index = range(len(df_control_ID.index))  ### person\n",
        "        BGs = df_control_ID[\"Breath.Group\"].unique()\n",
        "        for BG in BGs:\n",
        "          df_control_ID_BG = df_control_ID[df_control_ID[\"Breath.Group\"]  == BG]\n",
        "          df_control_ID_BG.index = range(len(df_control_ID_BG.index)) ## BG\n",
        "          if len(df_control_ID_BG) >= cut_c:\n",
        "            df_control_ID_BG.drop(df_control_ID_BG.tail(cut_c).index, inplace = True)\n",
        "            participant = participant.append([df_control_ID_BG], ignore_index = True)\n",
        "          else:\n",
        "            participant = participant.append([df_control_ID_BG], ignore_index = True)\n",
        "      cons_col_matched = cons_col_matched.append([participant], ignore_index = True) # add participant-level dataframe to group-level dataframe\n",
        "  return(cons_col_matched)"
      ],
      "metadata": {
        "id": "uM0OfrcDjAxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.9 Count Utterances**"
      ],
      "metadata": {
        "id": "lZ40kVIujNSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def countUtterances(df):\n",
        "  sum = 0\n",
        "  for ID in df[\"ID\"].unique():\n",
        "    subset_ID = df[df[\"ID\"] == ID]\n",
        "    sum = sum + len(subset_ID[\"Breath.Group\"].unique())\n",
        "  return(sum)"
      ],
      "metadata": {
        "id": "HmMl4xqRjQuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.10. Test if Remaining Vowel Difference is Significant**"
      ],
      "metadata": {
        "id": "ogrILNepjUHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ttest_vowelDifference(matched_participant_df, shorter_group):\n",
        "  if shorter_group == \"PWS\":\n",
        "    longer_group = \"Control\"\n",
        "  else:\n",
        "    longer_group = \"PWS\"\n",
        "\n",
        "  ttest_control = matched_participant_df[matched_participant_df[\"Group\"] == \"Control\"]\n",
        "  ttest_pws = matched_participant_df[matched_participant_df[\"Group\"] == \"PWS\"]\n",
        "\n",
        "  ttest_control = ttest_control.dropna()\n",
        "  ttest_pws = ttest_pws.dropna()\n",
        "\n",
        "  control_v =  ttest_control.mean()[\"Syllables\"]\n",
        "  pws_v =  ttest_pws.mean()[\"Syllables\"]\n",
        "\n",
        "  difference_v_matched = control_v - pws_v\n",
        "\n",
        "  df_v_matched_test = stats.ttest_ind(np.array(ttest_control['Syllables'].astype(float)),\n",
        "                      np.array(ttest_pws['Syllables']).astype(float))\n",
        "  if df_v_matched_test[1] >= 0.05:\n",
        "    level = \"insignificant\"\n",
        "  elif df_v_matched_test[1] < 0.05:\n",
        "    level = \"significant\"\n",
        "  else:\n",
        "    level = 'undetermined'\n",
        "  string11 = (f\"{longer_group} utterances that were longer than the mean average length of {shorter_group} utterances were shortened. \\nAfter matching, PWS had {round(pws_v,2)} vowels per utterance, while control participants had {round(control_v,2)} per utterance. \\nThe difference is reduced to {abs(round(difference_v_matched,2))}, which is statistically {level} (p = {round(df_v_matched_test[1],2)}).\")\n",
        "\n",
        "  return(string11)"
      ],
      "metadata": {
        "id": "l4jQSZn-jcbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.11. Test if Remaining Consonant Difference is Significant**"
      ],
      "metadata": {
        "id": "HRG75pL9jeTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ttest_conDifference(matched_participant_df, shorter_group):\n",
        "  if shorter_group == \"PWS\":\n",
        "    longer_group = \"Control\"\n",
        "  else:\n",
        "    longer_group = \"PWS\"\n",
        "  ttest_control = matched_participant_df[matched_participant_df[\"Group\"] == \"Control\"]\n",
        "  ttest_pws = matched_participant_df[matched_participant_df[\"Group\"] == \"PWS\"]\n",
        "\n",
        "  ttest_control = ttest_control.dropna()\n",
        "  ttest_pws = ttest_pws.dropna()\n",
        "\n",
        "  control_c =  ttest_control.mean()[\"Consonants\"]\n",
        "  pws_c =  ttest_pws.mean()[\"Consonants\"]\n",
        "\n",
        "  difference_c_matched = control_c - pws_c\n",
        "\n",
        "  df_c_matched_test = stats.ttest_ind(np.array(ttest_control['Consonants']).astype(float),\n",
        "                        np.array(ttest_pws['Consonants']).astype(float))\n",
        "  if df_c_matched_test[1] >= 0.05:\n",
        "    level = \"insignificant\"\n",
        "  elif df_c_matched_test[1] < 0.05:\n",
        "    level = \"significant\"\n",
        "  else:\n",
        "    level = \"undetermined\"\n",
        "  string11 = (f\"Control utterances that were longer than the mean average length of PWS utterances, were shortened. \\nAfter matching, PWS had {round(pws_c,2)} consonants per utterance, while control participants had {round(control_c,2)} per utterance. \\nThe difference is reduced to {abs(round(difference_c_matched,2))}, which is statistically {level} (p = {round(df_c_matched_test[1],2)}).\")\n",
        "\n",
        "  return(string11)"
      ],
      "metadata": {
        "id": "--_6cJ6RjpfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Match Across Groups (PWS vs. PWNS)**"
      ],
      "metadata": {
        "id": "RgiZsXmvjwxG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.1 Pre-Matching**"
      ],
      "metadata": {
        "id": "q7Q6cXmGkfed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add new column to dataframe that denotes participant's group membership\n",
        "frog = assign_group(frog)\n",
        "reading = assign_group(reading)"
      ],
      "metadata": {
        "id": "JA58WjaukCzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# account for case differences in annotation\n",
        "for i in range (0, len(frog)):\n",
        "  frog[\"FluencyStatus\"][i] = frog[\"FluencyStatus\"][i].lower().strip()\n",
        "for i in range (0, len(reading)):\n",
        "  reading[\"FluencyStatus\"][i] = reading[\"FluencyStatus\"][i].lower().strip()"
      ],
      "metadata": {
        "id": "TfG6felNhxEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# exclude disfluent utterances from further analysis\n",
        "frog_fluent = frog[frog[\"FluencyStatus\"] == \"fluent\"]\n",
        "frog_fluent.index = range(len(frog_fluent.index))\n",
        "reading_fluent = reading[reading[\"FluencyStatus\"] == \"fluent\"]\n",
        "reading_fluent.index = range(len(reading_fluent.index))"
      ],
      "metadata": {
        "id": "Zi8O66R2kCrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count vowels per utterance\n",
        "frog_vowels_fluent, pre_frog_vowel_avg_across_BG = count_vowels(frog_fluent, \"frog\")\n",
        "reading_vowels_fluent, pre_reading_vowel_avg_across_BG = count_vowels(reading_fluent, \"reading\")"
      ],
      "metadata": {
        "id": "b5MrZXEykCjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count consonants per utterance\n",
        "[frog_consonants_fluent, pre_frog_consonant_avg_across_BG]  = count_consonants(frog_fluent,'frog')\n",
        "[reading_consonants_fluent, pre_reading_consonants_avg_across_BG] = count_consonants(reading_fluent,'reading')"
      ],
      "metadata": {
        "id": "ion_rX8RkCeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#average # vowels per breath group for each participant\n",
        "frog_participant_vowel_avg_fluent = participant_vowel_avg(frog_vowels_fluent,'frog')\n",
        "reading_participant_vowel_avg_fluent = participant_vowel_avg(reading_vowels_fluent,'reading')"
      ],
      "metadata": {
        "id": "izzL2WnUkCZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#average # consonants per breath group for each participant\n",
        "frog_participant_cons_avg_fluent = participant_consonant_avg(frog_consonants_fluent,'frog')\n",
        "reading_participant_cons_avg_fluent = participant_consonant_avg(reading_consonants_fluent,'reading')"
      ],
      "metadata": {
        "id": "YDbVufymkCW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#average # per breath group for each participant and fluency status in frog\n",
        "if len(frog_participant_vowel_avg_fluent) > 1:\n",
        "  frog_participant_vowels_avg_pws = frog_participant_vowel_avg_fluent[frog_participant_vowel_avg_fluent[\"Group\"] == \"PWS\"]\n",
        "  frog_participant_vowels_avg_control = frog_participant_vowel_avg_fluent[frog_participant_vowel_avg_fluent[\"Group\"] == \"Control\"]\n",
        "  frog_participant_consonants_avg_pws = frog_participant_cons_avg_fluent[frog_participant_cons_avg_fluent[\"Group\"] == \"PWS\"]\n",
        "  frog_participant_consonants_avg_control = frog_participant_cons_avg_fluent[frog_participant_cons_avg_fluent[\"Group\"] == \"Control\"]\n",
        "else:\n",
        "  frog_participant_vowels_avg_pws = pd.DataFrame()\n",
        "  frog_participant_vowels_avg_control = pd.DataFrame()\n",
        "  frog_participant_consonants_avg_pws = pd.DataFrame()\n",
        "  frog_participant_consonants_avg_control = pd.DataFrame()"
      ],
      "metadata": {
        "id": "IpLW7eix0kBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#average # per breath group for each participant and fluency status in reading\n",
        "if len(reading_participant_vowel_avg_fluent) > 1:\n",
        "  reading_participant_vowels_avg_pws = reading_participant_vowel_avg_fluent[reading_participant_vowel_avg_fluent[\"Group\"] == \"PWS\"]\n",
        "  reading_participant_vowels_avg_control = reading_participant_vowel_avg_fluent[reading_participant_vowel_avg_fluent[\"Group\"] == \"Control\"]\n",
        "  reading_participant_consonants_avg_pws = reading_participant_cons_avg_fluent[reading_participant_cons_avg_fluent[\"Group\"] == \"PWS\"]\n",
        "  reading_participant_consonants_avg_control = reading_participant_cons_avg_fluent[reading_participant_cons_avg_fluent[\"Group\"] == \"Control\"]\n",
        "else:\n",
        "  reading_participant_vowels_avg_pws = pd.DataFrame()\n",
        "  reading_participant_vowels_avg_control = pd.DataFrame()\n",
        "  reading_participant_consonants_avg_pws = pd.DataFrame()\n",
        "  reading_participant_consonants_avg_control = pd.DataFrame()"
      ],
      "metadata": {
        "id": "9UVHrlfGz97_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compare group averages of number of vowels per utterance and number of consonants per utterance\n",
        "# frog\n",
        "string1, string2, string3, string4, string5, short_v_frog_fluent, short_c_frog_fluent, difference_v_frog_fluent, difference_c_frog_fluent, long_group_frog, short_group_frog = compare_groups(frog_participant_vowel_avg_fluent, frog_participant_cons_avg_fluent)\n",
        "\n",
        "print(string1)\n",
        "print(string2)\n",
        "print(string3)\n",
        "print(string4)\n",
        "print(string5)"
      ],
      "metadata": {
        "id": "dAhMo1I-kCTP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7683416e-9771-411b-8b83-a82279efff77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PWS produced on average 6.66 syllables per utterance, while Control participants produced 5.86 syllables on average.\n",
            "This means that there is a difference of 0.8 syllables per utterance.\n",
            "\n",
            "PWS produced on average 9.95 consonants per utterance, while Control participants produced 7.57 consonants on average.\n",
            "This means that there is a difference of 2.38 consonants per utterance.\n",
            "\n",
            "PWS participants produced longer utterances than Control on the frog condition.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compare group averages of number of vowels per utterance and number of consonants per utterance\n",
        "# reading\n",
        "string5, string6, string7, string8, string9, short_v_read_fluent, short_c_read_fluent, difference_v_read_fluent, difference_c_read_fluent, long_group_read, short_group_read  = compare_groups(reading_participant_vowel_avg_fluent, reading_participant_cons_avg_fluent)\n",
        "\n",
        "print(string5)\n",
        "print(string6)\n",
        "print(string7)\n",
        "print(string8)\n",
        "print(string9)"
      ],
      "metadata": {
        "id": "0ZRV_2GkkCG2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9098c551-905d-4d58-eb11-43a5beb81db0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Control produced on average 7.0 syllables per utterance, while PWS participants produced nan syllables on average.\n",
            "This means that there is a difference of nan syllables per utterance.\n",
            "\n",
            "Control produced on average 9.92 consonants per utterance, while PWS participants produced nan consonants on average.\n",
            "This means that there is a difference of nan consonants per utterance.\n",
            "\n",
            "Control participants produced longer utterances than PWS on the frog condition.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.2 Matching**"
      ],
      "metadata": {
        "id": "7cajLzTNlGbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# match number of vowels per utterance by cutting long utterances by the difference in average vowel number between groups\n",
        "matched_vowels_read_fluent = match_vowels(reading_vowels_fluent, short_group_read,  difference_v_read_fluent,'reading')\n",
        "matched_vowels_frog_fluent = match_vowels(frog_vowels_fluent, short_group_frog, difference_v_frog_fluent,'frog')"
      ],
      "metadata": {
        "id": "Gk_bIPkolTh-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d314d275-6448-4300-9bf1-27a52a3acd87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Only one group for reading condition. Matching not possible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# match number of consonants per utterance by cutting long control utterances by the difference in average consonant number between groups\n",
        "matched_consonants_read_fluent = match_consonants(reading_consonants_fluent, short_group_read, difference_c_read_fluent,'reading')\n",
        "matched_consonants_frog_fluent = match_consonants(frog_consonants_fluent, short_group_frog, difference_c_frog_fluent,'frog')"
      ],
      "metadata": {
        "id": "qIfob_WllaJf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "508bdeea-d22e-421c-cc73-f0649e706449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Only one group for reading condition. Matching not possible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if np.isnan(difference_c_read_fluent):\n",
        "  difference_c_read_fluent = 0\n",
        "if np.isnan(difference_c_frog_fluent):\n",
        "  difference_c_frog_fluent = 0\n",
        "if np.isnan(difference_v_read_fluent):\n",
        "  difference_v_read_fluent = 0\n",
        "if np.isnan(difference_c_frog_fluent):\n",
        "  difference_v_frog_fluent = 0\n",
        "\n",
        "print(f\"{long_group_read} utterances were cut by {round(difference_v_read_fluent)} vowels and {round(difference_c_read_fluent)} consonants in the reading condition.\")\n",
        "print(f\"{long_group_frog} utterances were cut by {round(difference_v_frog_fluent)} vowels and {round(difference_c_frog_fluent)} consonants in the frog condition.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7CRgioe9niq",
        "outputId": "b86469d4-0556-438b-e11d-b93d301320c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Control utterances were cut by 0 vowels and 0 consonants in the reading condition.\n",
            "PWS utterances were cut by 1 vowels and 2 consonants in the frog condition.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.3 Post-Matching**"
      ],
      "metadata": {
        "id": "FovN4J0_lm4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# combined shortened dataframe with original dataframe\n",
        "if short_group_frog == \"PWS\":\n",
        "  matched_vowels_frog_fluent = matched_vowels_frog_fluent.append(frog_vowels_fluent[frog_vowels_fluent[\"Group\"]==\"PWS\"], ignore_index=True)\n",
        "  matched_consonants_frog_fluent =  matched_consonants_frog_fluent.append(frog_consonants_fluent[frog_consonants_fluent[\"Group\"]==\"PWS\"], ignore_index=True)\n",
        "elif short_group_frog == \"Control\":\n",
        "  matched_vowels_frog_fluent = matched_vowels_frog_fluent.append(frog_vowels_fluent[frog_vowels_fluent[\"Group\"]==\"Control\"], ignore_index=True)\n",
        "  matched_consonants_frog_fluent = matched_consonants_frog_fluent.append(frog_consonants_fluent[frog_consonants_fluent[\"Group\"]==\"Control\"], ignore_index=True)"
      ],
      "metadata": {
        "id": "H67DM8G9lsHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combined shortened dataframe with original dataframe\n",
        "if short_group_read == \"PWS\":\n",
        "  matched_vowels_reading_fluent = matched_vowels_read_fluent.append(reading_vowels_fluent[reading_vowels_fluent[\"Group\"]==\"PWS\"], ignore_index=True)\n",
        "  matched_consonants_reading_fluent =  matched_consonants_read_fluent.append(reading_consonants_fluent[reading_consonants_fluent[\"Group\"]==\"PWS\"], ignore_index=True)\n",
        "elif short_group_read == \"Control\":\n",
        "  matched_vowels_reading_fluent = matched_vowels_read_fluent.append(reading_vowels_fluent[reading_vowels_fluent[\"Group\"]==\"Control\"], ignore_index=True)\n",
        "  matched_consonants_reading_fluent = matched_consonants_read_fluent.append(reading_consonants_fluent[reading_consonants_fluent[\"Group\"]==\"Control\"], ignore_index=True)"
      ],
      "metadata": {
        "id": "0sdlc9C8hvBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count vowels per utterance after matching\n",
        "[post_frog_vowels_fluent, post_frog_vowel]  = count_vowels(matched_vowels_frog_fluent,'frog')\n",
        "[post_reading_vowels_fluent, post_reading_vowel]  = count_vowels(matched_vowels_read_fluent,'reading')"
      ],
      "metadata": {
        "id": "VJSLilkrlrzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# average # vowels per breath group for each participant after matching\n",
        "post_frog_participant_vowels_avg_fluent = participant_vowel_avg(post_frog_vowels_fluent, 'frog')\n",
        "post_reading_participant_vowels_avg_fluent = participant_vowel_avg(post_reading_vowels_fluent,'reading')"
      ],
      "metadata": {
        "id": "I8KoMIN8lriU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count consonants per utterance after matching\n",
        "[post_frog_consonants_fluent, post_frog_consonant_avg_fluent]  = count_consonants(matched_consonants_frog_fluent, 'frog')\n",
        "[post_reading_consonants_fluent, post_reading_consonant_avg_fluent]  = count_consonants(matched_consonants_read_fluent,'reading')"
      ],
      "metadata": {
        "id": "nHpYQcpplrPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#average # consonants per breath group for each participant after matching\n",
        "post_frog_participant_cons_avg_fluent = participant_consonant_avg(post_frog_consonants_fluent, 'frog')\n",
        "post_reading_participant_cons_avg_fluent = participant_consonant_avg(post_reading_consonants_fluent,'reading')"
      ],
      "metadata": {
        "id": "PyVw04wUmENk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compare group averages of number of vowels per utterance and number of consonants per utterance\n",
        "# frog\n",
        "string1, string2, string3, string4, string5, short_v_frog_fluent, short_c_frog_fluent, difference_v_frog_fluent, difference_c_frog_fluent, long_group_frog, short_group_frog = compare_groups(post_frog_participant_vowels_avg_fluent, post_frog_participant_cons_avg_fluent)\n",
        "\n",
        "print(string1)\n",
        "print(string2)\n",
        "print(string3)\n",
        "print(string4)\n",
        "print(string5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9DRGV33NTzM",
        "outputId": "9697a20d-940b-43f8-84fd-f74d88a9e95b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PWS produced on average 5.95 syllables per utterance, while Control participants produced 5.86 syllables on average.\n",
            "This means that there is a difference of 0.09 syllables per utterance.\n",
            "\n",
            "PWS produced on average 8.36 consonants per utterance, while Control participants produced 7.57 consonants on average.\n",
            "This means that there is a difference of 0.79 consonants per utterance.\n",
            "\n",
            "PWS participants produced longer utterances than Control on the frog condition.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compare group averages of number of vowels per utterance and number of consonants per utterance\n",
        "# reading\n",
        "string5, string6, string7, string8, string9, short_v_read_fluent, short_c_read_fluent, difference_v_read_fluent, difference_c_read_fluent, long_group_read, short_group_read  = compare_groups(post_reading_participant_vowels_avg_fluent, post_reading_participant_cons_avg_fluent)\n",
        "\n",
        "print(string5)\n",
        "print(string6)\n",
        "print(string7)\n",
        "print(string8)\n",
        "print(string9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUJ8WqT5Npgl",
        "outputId": "186137f3-63d6-4ede-da3c-58bb669d5abc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Control produced on average 7.0 syllables per utterance, while PWS participants produced nan syllables on average.\n",
            "This means that there is a difference of nan syllables per utterance.\n",
            "\n",
            "Control produced on average 9.92 consonants per utterance, while PWS participants produced nan consonants on average.\n",
            "This means that there is a difference of nan consonants per utterance.\n",
            "\n",
            "Control participants produced longer utterances than PWS on the frog condition.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Significance After Matching**"
      ],
      "metadata": {
        "id": "GoUUyRSJmSt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test if average number of vowels per breathgroup is still significantly different between groups after matching\n",
        "# frog\n",
        "string1 = ttest_vowelDifference(post_frog_participant_vowels_avg_fluent, short_group_frog)\n",
        "print(string1)"
      ],
      "metadata": {
        "id": "JSZOIJ2ymLqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test if average number of vowels per breathgroup is still significantly different between groups after matching\n",
        "# reading\n",
        "string2 = ttest_vowelDifference(post_reading_participant_vowels_avg_fluent, short_group_read)\n",
        "print(string2)"
      ],
      "metadata": {
        "id": "wVZSKX_AmYRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test if average number of consonants per breathgroup is still significantly different between groups after matching\n",
        "# frog\n",
        "string1 = ttest_conDifference(post_frog_participant_cons_avg_fluent, short_group_frog)\n",
        "print(string1)"
      ],
      "metadata": {
        "id": "it6d3-DGmYCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test if average number of consonants per breathgroup is still significantly different between groups after matching\n",
        "# reading\n",
        "string2 = ttest_conDifference(post_reading_participant_cons_avg_fluent, short_group_read)\n",
        "print(string2)"
      ],
      "metadata": {
        "id": "QZV9TO-WmX0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Count Utterances in Each Category**"
      ],
      "metadata": {
        "id": "rwJtN7x0m6EU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pws_frog_fluent = post_frog_vowels_fluent[post_frog_vowels_fluent[\"Group\"] == \"PWS\"]\n",
        "control_frog_fluent = post_frog_vowels_fluent[post_frog_vowels_fluent[\"Group\"] == \"Control\"]\n",
        "pws_read_fluent = post_reading_vowels_fluent[post_reading_vowels_fluent[\"Group\"] == \"PWS\"]\n",
        "control_read_fluent = post_reading_vowels_fluent[post_reading_vowels_fluent[\"Group\"] == \"Control\"]"
      ],
      "metadata": {
        "id": "jh2d1zTGRank"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_reading_control_fluent = countUtterances(control_read_fluent)\n",
        "number_frog_control_fluent = countUtterances(control_frog_fluent)\n",
        "number_reading_pws_fluent = countUtterances(pws_read_fluent)\n",
        "number_frog_pws_fluent = countUtterances(pws_frog_fluent)"
      ],
      "metadata": {
        "id": "H0u3HXjlm_A3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"There are {number_reading_pws_fluent} utterances produced by PWS in the reading condition and {number_reading_control_fluent} utterance produced by control.\")\n",
        "print(f\"\\nThere are {number_frog_pws_fluent} utterances produced by PWS in the frog condition and {number_frog_control_fluent} utterance produced by control.\")"
      ],
      "metadata": {
        "id": "F8csnmaNnH50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ad66815-6d20-4e5d-a7b9-c6d69192a1ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 0 utterances produced by PWS in the reading condition and 13 utterance produced by control.\n",
            "\n",
            "There are 39 utterances produced by PWS in the frog condition and 7 utterance produced by control.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Create Output Dataframes**"
      ],
      "metadata": {
        "id": "WHcsccAMnCwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "post_reading_vowels_fluent.drop([\"Unmached_Vowels\"],axis=1 , inplace = True)\n",
        "post_frog_vowels_fluent.drop([\"Unmached_Vowels\"],axis=1 , inplace = True)\n",
        "post_reading_consonants_fluent.drop([\"Unmatched_Cons\"],axis=1 , inplace = True)\n",
        "post_frog_consonants_fluent.drop([\"Unmatched_Cons\"],axis=1 , inplace = True)"
      ],
      "metadata": {
        "id": "FKy3yoT4nN-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Save**"
      ],
      "metadata": {
        "id": "HZkFiG3wnpC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/ATAS_Plus/Duration_Metrics"
      ],
      "metadata": {
        "id": "8xWNLKqCntbp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e1f35e0-9319-4195-bcce-1f948293a349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/ATAS_Plus/Duration_Metrics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir = \"3.MLU_Matched\"\n",
        "\n",
        "if os.path.exists(dir) == False:\n",
        "  os.mkdir(dir)"
      ],
      "metadata": {
        "id": "ipfwIIxXntK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/ATAS_Plus/Duration_Metrics/3.MLU_Matched/"
      ],
      "metadata": {
        "id": "cXqSfEhrnsqp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "804d4918-4b30-4c33-91e4-35cd1aae473d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/ATAS_Plus/Duration_Metrics/3.MLU_Matched\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# export\n",
        "post_reading_vowels_fluent.to_excel(\"matchedVowels_reading_FLUENT.xlsx\")\n",
        "post_reading_consonants_fluent.to_excel(\"matchedConsonants_reading_FLUENT.xlsx\")\n",
        "post_frog_vowels_fluent.to_excel(\"matchedVowels_frog_FLUENT.xlsx\")\n",
        "post_frog_consonants_fluent.to_excel(\"matchedConsonants_frog_FLUENT.xlsx\")"
      ],
      "metadata": {
        "id": "CaKywZa-ns10"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}