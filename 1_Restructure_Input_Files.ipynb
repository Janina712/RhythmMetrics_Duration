{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Janina712/RhythmMetrics_Duration/blob/main/1_Restructure_Input_Files.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8U-SKHbEScsF"
      },
      "source": [
        "# **User Input**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IDs_reading = ['24fa']  ## add participant IDs here\n",
        "IDs_frog = ['24fa']"
      ],
      "metadata": {
        "id": "N5X_QfOwtA8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "275yxZPbDyR5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45b40203-5029-4a0d-a833-760583b18278"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/ATAS_Plus/Duration_Metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLxIGUDJFhzT",
        "outputId": "ac8a0aae-43e8-4461-b0cf-d289eda4f075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/gdrive/MyDrive/ATAS_Plus/Duration_Metrics'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaMzZqcQCk1B"
      },
      "source": [
        "**0. Imports & Set Up**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyncVYrgCai8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFKko_gcCuD5"
      },
      "source": [
        "**1. Load Data Files**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_sWZ_Zu1JSA"
      },
      "outputs": [],
      "source": [
        "extention = ['txt', 'TextGrid', 'csv']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xXtaDr61L1m"
      },
      "outputs": [],
      "source": [
        "# get required shape of dataframes\n",
        "max_read_txt = 0\n",
        "max_read_TextGrid = 0\n",
        "max_read_csv = 0\n",
        "max_frog_txt = 0\n",
        "max_frog_TextGrid = 0\n",
        "max_frog_csv = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjrfuh3p1XTq",
        "outputId": "78f0e5c3-8ba5-4891-abf4-46dec7212ea5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No .txt file found for  NM102\n",
            "Warning: No TextGrid file found for  NM102\n",
            "Warning: No .csv file found for  NM102\n",
            "Warning: No .txt file found for  RS_C_16_XE\n",
            "Warning: No TextGrid file found for  RS_C_16_XE\n",
            "Warning: No .csv file found for  RS_C_16_XE\n"
          ]
        }
      ],
      "source": [
        "# assemble input file names (frog)\n",
        "for ID in IDs_frog:\n",
        "  for ext in extention:\n",
        "    if ext == 'txt':\n",
        "      if os.path.isfile(ID + '_' + 'frog' + '.' + ext) == False:\n",
        "        print(f\"Warning: No .txt file found for \", ID)\n",
        "      else:\n",
        "        if len(pd.read_csv(ID + '_' + 'frog' + '.' + ext)) > max_frog_txt:\n",
        "          max_frog_txt = len(pd.read_csv(ID + '_' + 'frog' + '.' + ext))\n",
        "    elif ext == 'TextGrid':\n",
        "      if os.path.isfile(ID + '_' + 'frog' + '.' + ext) == False:\n",
        "        print(f\"Warning: No TextGrid file found for \", ID)\n",
        "      else:\n",
        "        if len(pd.read_csv(ID + '_' + 'frog' + '.' + ext, encoding='utf16')) > max_frog_TextGrid:\n",
        "          max_frog_TextGrid = len(pd.read_csv(ID + '_' + 'frog' + '.' + ext, encoding='utf16'))\n",
        "    elif ext == 'csv':\n",
        "      if os.path.isfile(ID + '_FS_' + 'frog' + '.' + ext) == False:\n",
        "        print(f\"Warning: No .csv file found for \", ID)\n",
        "      else:\n",
        "        if len(pd.read_csv(ID + '_FS_' + 'frog' + '.' + ext)) <  max_frog_csv:\n",
        "          max_frog_csv = max_frog_csv\n",
        "        elif len(pd.read_csv(ID + '_FS_' + 'frog' + '.' + ext)) > max_frog_csv:\n",
        "          max_frog_csv = len(pd.read_csv(ID + '_FS_' + 'frog' + '.' + ext))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# assemble input file names (reading)\n",
        "for ID in IDs_reading:\n",
        "  for ext in extention:\n",
        "    if ext == 'txt':\n",
        "      if os.path.isfile(ID + '_' + 'reading' + '.' + ext) == False:\n",
        "        print(f\"Warning: No .txt file found for \", ID)\n",
        "      else:\n",
        "        if len(pd.read_csv(ID + '_' + 'reading' + '.' + ext)) > max_read_txt:\n",
        "          max_read_txt = len(pd.read_csv(ID + '_' + 'reading' + '.' + ext))\n",
        "    elif ext == 'TextGrid':\n",
        "      if os.path.isfile(ID + '_' + 'reading' + '.' + ext) == False:\n",
        "        print(f\"Warning: No TextGrid file found for \", ID)\n",
        "      else:\n",
        "        if len(pd.read_csv(ID + '_' + 'reading' + '.' + ext, encoding='utf16')) > max_read_TextGrid:\n",
        "          max_read_TextGrid = len(pd.read_csv(ID + '_' + 'reading' + '.' + ext, encoding='utf16'))\n",
        "    elif ext == 'csv':\n",
        "      if os.path.isfile(ID + '_FS_' + 'reading' + '.' + ext) == False:\n",
        "        print(f\"Warning: No .csv file found for \", ID)\n",
        "      else:\n",
        "        if len(pd.read_csv(ID + '_FS_' + 'reading' + '.' + ext)) <  max_read_csv:\n",
        "          max_read_csv = max_read_csv\n",
        "        elif len(pd.read_csv(ID + '_FS_' + 'reading' + '.' + ext)) > max_read_csv:\n",
        "          max_read_csv = len(pd.read_csv(ID + '_FS_' + 'reading' + '.' + ext))"
      ],
      "metadata": {
        "id": "wpPeP8IJD74x",
        "outputId": "0e4b85ec-9f5f-45e9-bd75-0e06d5329dde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No .txt file found for  RS_C_16_XE\n",
            "Warning: No TextGrid file found for  RS_C_16_XE\n",
            "Warning: No .csv file found for  RS_C_16_XE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ti_szRBY2BRL"
      },
      "outputs": [],
      "source": [
        "# initialize dataframes\n",
        "df_read_txt = pd.DataFrame(index=range(max_read_txt),columns=range(1))\n",
        "df_read_TextGrid = pd.DataFrame(index=range(max_read_TextGrid),columns=range(1))\n",
        "df_read_csv = pd.DataFrame(index=range(max_read_csv), columns=range(1))\n",
        "df_frog_txt = pd.DataFrame(index=range(max_frog_txt),columns=range(1))\n",
        "df_frog_TextGrid = pd.DataFrame(index=range(max_frog_TextGrid),columns=range(1))\n",
        "df_frog_csv = pd.DataFrame(index=range(max_frog_csv), columns=range(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOhutsCi2Tiq",
        "outputId": "6414d191-fb9b-4664-d114-968dbb3d5c89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No .txt file found for  NM102\n",
            "Warning: No TextGrid file found for  NM102\n",
            "Warning: No .csv file found for  NM102\n",
            "Warning: No .txt file found for  RS_C_16_XE\n",
            "Warning: No TextGrid file found for  RS_C_16_XE\n",
            "Warning: No .csv file found for  RS_C_16_XE\n"
          ]
        }
      ],
      "source": [
        "#import frog data\n",
        "for ID in IDs_frog:\n",
        "  for ext in extention:\n",
        "      if ext == 'txt':\n",
        "        if os.path.isfile(ID + '_' + 'frog' + '.' + ext) :\n",
        "          df_frog_txt[ID] = pd.read_csv(ID + '_' + 'frog' + '.' + ext, header = None, sep=\"/t\")\n",
        "        else:\n",
        "          print(f\"Warning: No .txt file found for \", ID)\n",
        "      elif ext == 'TextGrid':\n",
        "        if os.path.isfile(ID + '_' + 'frog' + '.' + ext):\n",
        "          df_frog_TextGrid[ID] = pd.read_csv(ID + '_' + 'frog'+ '.' + ext, encoding ='utf16')\n",
        "        else:\n",
        "          print(f\"Warning: No TextGrid file found for \", ID)\n",
        "      elif ext == 'csv':\n",
        "        if os.path.isfile(ID + '_FS_' + 'frog' + '.' + ext):\n",
        "          df_frog_csv[ID] = pd.read_csv(ID + '_FS_' + 'frog' + '.' + ext)\n",
        "        else:\n",
        "          print(f\"Warning: No .csv file found for \", ID)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import reading data\n",
        "for ID in IDs_reading:\n",
        "  for ext in extention:\n",
        "      if ext == 'txt':\n",
        "        if os.path.isfile(ID + '_' + 'reading' + '.' + ext):\n",
        "          df_read_txt[ID] = pd.read_csv(ID + '_' + 'reading' + '.' + ext, header = None)\n",
        "        else:\n",
        "          print(f\"Warning: No .txt file found for \", ID)\n",
        "      elif ext == 'TextGrid':\n",
        "        if os.path.isfile(ID + '_' + 'reading' + '.' + ext):\n",
        "          df_read_TextGrid[ID] = pd.read_csv(ID + '_' + 'reading' + '.' + ext, encoding='utf16')\n",
        "        else:\n",
        "          print(f\"Warning: No TextGrid file found for \", ID)\n",
        "      elif ext == 'csv':\n",
        "        if os.path.isfile(ID + '_FS_' + 'reading' + '.' + ext):\n",
        "          df_read_csv[ID] = pd.read_csv(ID + '_FS_' + 'reading' + '.' + ext)\n",
        "        else:\n",
        "          print(f\"Warning: No .csv file found for \", ID)"
      ],
      "metadata": {
        "id": "aLnnr4YfEfz2",
        "outputId": "f0d2cc8a-7a6c-42d5-c115-7bc7d6ee525d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No .txt file found for  RS_C_16_XE\n",
            "Warning: No TextGrid file found for  RS_C_16_XE\n",
            "Warning: No .csv file found for  RS_C_16_XE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOb8WxtNNyww"
      },
      "outputs": [],
      "source": [
        "df_read_txt_wide = pd.DataFrame()\n",
        "df_frog_txt_wide = pd.DataFrame()\n",
        "df_read_TextGrid_wide = pd.DataFrame()\n",
        "df_frog_TextGrid_wide = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkPL974QyJY5"
      },
      "source": [
        "**2. Combine txt Files**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_j2oUQVCOqw",
        "outputId": "52082e7b-d111-4334-c6da-4ef2d2047919",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-c97dfcc0a78a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mID\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mIDs_reading\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mdf_read_txt_wide\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_read_txt_wide\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_read_txt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mID\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mIDs_frog\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mdf_frog_txt_wide\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_frog_txt_wide\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_frog_txt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    393\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_indexing_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'RS_C_16_XE'"
          ]
        }
      ],
      "source": [
        "for ID in IDs_reading:\n",
        "  df_read_txt_wide = df_read_txt_wide.append(df_read_txt[ID].str.split(\"\\t\", expand = True, n = 4), ignore_index=True)\n",
        "\n",
        "for ID in IDs_frog:\n",
        "  df_frog_txt_wide = df_frog_txt_wide.append(df_frog_txt[ID].str.split(\"\\t\", expand = True, n = 4), ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAC5Dt3u-q2g"
      },
      "outputs": [],
      "source": [
        "if df_read_txt_wide.empty:\n",
        "  pass\n",
        "else:\n",
        "  df_read_txt_wide.drop(columns=[0, 1], inplace = True)\n",
        "  df_read_txt_wide.rename(columns={2: 'Onset', 3: 'Offset', 4: \"Utterance\"}, inplace=True)\n",
        "\n",
        "if df_frog_txt_wide.empty:\n",
        "  pass\n",
        "else:\n",
        "  df_frog_txt_wide.drop(columns=[0, 1], inplace = True)\n",
        "  df_frog_txt_wide.rename(columns={2: 'Onset', 3: 'Offset', 4: \"Utterance\"}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjF1YehOO29w"
      },
      "outputs": [],
      "source": [
        "names_read = []\n",
        "name_col_read = []\n",
        "names_frog = []\n",
        "name_col_frog = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdJsaSB_OFe5"
      },
      "outputs": [],
      "source": [
        "for ID in IDs_reading:\n",
        "  names_read.append([ID for i in range(len(df_read_txt))])\n",
        "for n in range(0,len(IDs_reading)):\n",
        "  name_col_read = name_col_read + names_read[n]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neEx7ipxXGjI"
      },
      "outputs": [],
      "source": [
        "for ID in IDs_frog:\n",
        "  names_frog.append([ID for i in range(len(df_frog_txt))])\n",
        "for n in range(0,len(IDs_frog)):\n",
        "  name_col_frog = name_col_frog + names_frog[n]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xM5k9Eq7Wsdt"
      },
      "outputs": [],
      "source": [
        "df_read_txt_wide.insert(0, 'ID', name_col_read)\n",
        "df_frog_txt_wide.insert(0, 'ID', name_col_frog)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvGlDgLOv1ic"
      },
      "outputs": [],
      "source": [
        "df_read_txt_wide.dropna(inplace=True)\n",
        "df_frog_txt_wide.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlUrMDK1JU_O"
      },
      "outputs": [],
      "source": [
        "# add Fluencystatus column in reading\n",
        "FS_col = pd.DataFrame()\n",
        "for ID in IDs_reading:\n",
        "  subset_ID = df_read_txt_wide[df_read_txt_wide[\"ID\"] == ID]\n",
        "  subset_ID.index = range(len(subset_ID.index)) # reset index\n",
        "  FS = df_read_csv[ID].head(len(subset_ID)) # get FS without NANs\n",
        "  subset_ID[\"FluencyStatus\"] = FS               # add to sub dataframe\n",
        "  FS_col = FS_col.append([subset_ID], ignore_index = True)\n",
        "df_read_txt_wide = FS_col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMCU7uEkP6NL"
      },
      "outputs": [],
      "source": [
        "if df_read_txt_wide.empty:\n",
        "  print(0)\n",
        "else:\n",
        "  df_read_txt_wide['FluencyStatus'].isnull().sum()  # should be zero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEbZg_TQPQ79"
      },
      "outputs": [],
      "source": [
        "# add Fluencystatus column in interview\n",
        "FS_col = pd.DataFrame()\n",
        "for ID in IDs_frog:\n",
        "  subset_ID = df_frog_txt_wide[df_frog_txt_wide[\"ID\"] == ID]\n",
        "  subset_ID.index = range(len(subset_ID.index)) # reset index\n",
        "  FS = df_frog_csv[ID].head(len(subset_ID)) # get FS without NANs\n",
        "  subset_ID[\"FluencyStatus\"] = FS               # add to sub dataframe\n",
        "  FS_col = FS_col.append([subset_ID], ignore_index = True)\n",
        "df_frog_txt_wide = FS_col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7Zut0vdQtrb"
      },
      "outputs": [],
      "source": [
        "if df_frog_txt_wide.empty:\n",
        "  print(0)\n",
        "else:\n",
        "  df_frog_txt_wide['FluencyStatus'].isnull().sum()  # should be zero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5m5E6JR5un8o"
      },
      "outputs": [],
      "source": [
        "df_frog_txt_wide"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOzAhdP-iBOx"
      },
      "source": [
        "**3.1 Combine TextGrid Files: Reading**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "up2r3P9TGZar"
      },
      "outputs": [],
      "source": [
        "IntervalSizeString = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPWejzzDGP0D"
      },
      "outputs": [],
      "source": [
        "for ID in IDs_reading:\n",
        "  IntervalSizeString.append(df_read_TextGrid[ID][11])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-iQdc84J6zY"
      },
      "outputs": [],
      "source": [
        "IntervalSize = []\n",
        "for i in range(0,len(IntervalSizeString)):\n",
        "  for z in IntervalSizeString[i].split():\n",
        "    if z.isdigit():\n",
        "        IntervalSize.append(int(z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tH2uEl-ELdrA"
      },
      "outputs": [],
      "source": [
        "if IntervalSize == []:\n",
        "  maxLength = 0\n",
        "else:\n",
        "  maxLength = max(IntervalSize)\n",
        "\n",
        "lastRow = len(df_read_TextGrid)\n",
        "n = -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7W29-f6OnBr"
      },
      "outputs": [],
      "source": [
        "for ID in IDs_reading:\n",
        "  n = n + 1\n",
        "  endRow = IntervalSize[n] * 4 + 12\n",
        "  df_read_TextGrid[ID][endRow:lastRow] = np.NaN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvo4fItkYi0o"
      },
      "outputs": [],
      "source": [
        "if df_read_TextGrid.empty:\n",
        "  pass\n",
        "else:\n",
        "  for c in range(0,12):\n",
        "    df_read_TextGrid.drop([c], inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDlpRanbZJN5"
      },
      "outputs": [],
      "source": [
        "for ID in IDs_reading:\n",
        "  df_read_TextGrid_wide = df_read_TextGrid_wide.append(df_read_TextGrid[ID].str.split(\" = \", expand = True, n = 1), ignore_index=True)  ## get duration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Z08gOb2MyZv"
      },
      "outputs": [],
      "source": [
        "if df_read_TextGrid_wide.empty:\n",
        "  pass\n",
        "else:\n",
        "  df_read_TextGrid_wide = df_read_TextGrid_wide[df_read_TextGrid_wide[0].str.contains(\"xmin|xmax|text\") == True]\n",
        "  onsets = df_read_TextGrid_wide[df_read_TextGrid_wide[0].str.contains(\"xmin\") == True]\n",
        "  offsets = df_read_TextGrid_wide[df_read_TextGrid_wide[0].str.contains(\"xmax\") == True]\n",
        "  sounds = df_read_TextGrid_wide[df_read_TextGrid_wide[0].str.contains(\"text\") == True]\n",
        "  onsets.index = range(len(onsets.index))\n",
        "  offsets.index = range(len(offsets.index))\n",
        "  sounds.index = range(len(sounds.index))\n",
        "  duration = []\n",
        "  for i in range (0,(len(offsets))):\n",
        "    duration.append(float(offsets[1][i]) - float(onsets[1][i]))\n",
        "  duration = pd.DataFrame(duration)\n",
        "  read_TextGrid_duration = pd.concat([sounds, onsets, offsets, duration], axis=1)\n",
        "  read_TextGrid_duration.columns = ['text', 'Sound', 'min', 'Onset', 'max','Offset','Duration']\n",
        "  read_TextGrid_duration.drop(['text', 'min', 'max'], axis=1, inplace = True)\n",
        "  ID_col = pd.DataFrame(columns=range(1))\n",
        "  n = -1\n",
        "  for ID in IDs_reading:\n",
        "    n = n + 1\n",
        "    ID_col = ID_col.append([ID]*IntervalSize[n])\n",
        "  ID_col.index = range(len(ID_col.index))\n",
        "  read_TextGrid_duration = pd.concat([ID_col, read_TextGrid_duration], axis=1)\n",
        "  read_TextGrid_duration.columns = ['ID','Sound', 'Onset', 'Offset','Duration']\n",
        "  print(read_TextGrid_duration)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWYDhQyVrcdP"
      },
      "source": [
        "**3.2 Combine TextGrid Files: Frog**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GyKk1jHRljH"
      },
      "outputs": [],
      "source": [
        "IntervalSizeString = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbQEMhwTlnb3"
      },
      "outputs": [],
      "source": [
        "for ID in IDs_frog:\n",
        "  IntervalSizeString.append(df_frog_TextGrid[ID][11])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vit68lOSlnW6"
      },
      "outputs": [],
      "source": [
        "IntervalSize = []\n",
        "for i in range(0,len(IntervalSizeString)):\n",
        "  for z in IntervalSizeString[i].split():\n",
        "    if z.isdigit():\n",
        "        IntervalSize.append(int(z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LJKKN60rnWX"
      },
      "outputs": [],
      "source": [
        "if IntervalSize == []:\n",
        "  maxLength = 0\n",
        "else:\n",
        "  maxLength = max(IntervalSize)\n",
        "\n",
        "lastRow = len(df_frog_TextGrid)\n",
        "n = -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwCpOxnQrnTq"
      },
      "outputs": [],
      "source": [
        "for ID in IDs_frog:\n",
        "  n = n + 1\n",
        "  endRow = IntervalSize[n] * 4 + 12\n",
        "  df_frog_TextGrid[ID][endRow:lastRow] = np.NaN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUs6g8rTrnQa"
      },
      "outputs": [],
      "source": [
        "if df_frog_TextGrid.empty:\n",
        "  pass\n",
        "else:\n",
        "  for c in range(0,12):\n",
        "    df_frog_TextGrid.drop([c], inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rv0j_S4QrnM9"
      },
      "outputs": [],
      "source": [
        "for ID in IDs_frog:\n",
        "  df_frog_TextGrid_wide = df_frog_TextGrid_wide.append(df_frog_TextGrid[ID].str.split(\" = \", expand = True, n = 1), ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ta3-iYokrnJh"
      },
      "outputs": [],
      "source": [
        "if df_frog_TextGrid_wide.empty:\n",
        "  pass\n",
        "else:\n",
        "  df_frog_TextGrid_wide = df_frog_TextGrid_wide[df_frog_TextGrid_wide[0].str.contains(\"xmin|xmax|text\") == True]\n",
        "  onsets = df_frog_TextGrid_wide[df_frog_TextGrid_wide[0].str.contains(\"xmin\") == True]\n",
        "  offsets = df_frog_TextGrid_wide[df_frog_TextGrid_wide[0].str.contains(\"xmax\") == True]\n",
        "  sounds = df_frog_TextGrid_wide[df_frog_TextGrid_wide[0].str.contains(\"text\") == True]\n",
        "  onsets.index = range(len(onsets.index))\n",
        "  offsets.index = range(len(offsets.index))\n",
        "  sounds.index = range(len(sounds.index))\n",
        "  duration = []\n",
        "  for i in range (0,(len(offsets))):\n",
        "    duration.append(float(offsets[1][i]) - float(onsets[1][i]))\n",
        "  duration = pd.DataFrame(duration)\n",
        "  frog_TextGrid_duration = pd.concat([sounds, onsets, offsets, duration], axis=1)\n",
        "  frog_TextGrid_duration.columns = ['text', 'Sound', 'min', 'Onset', 'max','Offset','Duration']\n",
        "  frog_TextGrid_duration.drop(['text', 'min', 'max'], axis=1, inplace = True)\n",
        "  ID_col = pd.DataFrame(columns=range(1))\n",
        "  n = -1\n",
        "  for ID in IDs_frog:\n",
        "    n = n + 1\n",
        "    ID_col = ID_col.append([ID]*IntervalSize[n])\n",
        "  ID_col.index = range(len(ID_col.index))\n",
        "  frog_TextGrid_duration = pd.concat([ID_col, frog_TextGrid_duration], axis=1)\n",
        "  frog_TextGrid_duration.columns = ['ID', 'Sound', 'Onset', 'Offset','Duration']\n",
        "  print(frog_TextGrid_duration)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4Ll87TV4lxH"
      },
      "source": [
        "**4. Add Info to TextGrid Files**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXmLZ31U-zBC"
      },
      "source": [
        "**4.1 Sound Inventory**\n",
        "\n",
        "(May throw error if new file contains additional sounds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTDsHOncUTiy"
      },
      "outputs": [],
      "source": [
        "vowels = np.array([ '\"iː\" ','\"aɪə\" ', '\"ɛ\" ', '\"ɪ\" ', '\"æ\" ', '\"ɑː\" ', '\"ʊ\" ', '\"aɪ\" ', '\"oʊ\" ','\"ə\" ', '\"uː\" ', '\"ɜː\" ','\"ɔː\" ', '\"ʌ\" ', '\"ɚ\" ', '\"ɐ\" ', '\"ɑːɹ\" ', '\"aʊ\" ', '\"eɪ\" ', '\"i\" ', '\"ɔːɹ\" ', '\"ɔ\" ', '\"ᵻ\" ', '\"ɛɹ\" ', '\"ɔɪ\" ', '\"əl\" ', '\"ɔː\" ', '\"ʊɹ\" ', '\"ɪɹ\" ' ,'\"iə\" ', '\"ɔː\" '])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2C1_GBWxUY7z"
      },
      "outputs": [],
      "source": [
        "consonants = np.array([ '\"h\" ', '\"z\" ','\"ɡ\" ', '\"ɾ\" ', '\"ŋ\" ', '\"d\" ', '\"ɹ\" ', '\"s\" ', '\"t\" ', '\"n\" ', '\"f\" ', '\"l\" ', '\"k\" ','\"m\" ', '\"ð\" ', '\"dʒ\" ', '\"p\" ', '\"tʃ\" ', '\"b\" ',  '\"w\" ', '\"v\" ', '\"ʃ\" ', '\"θ\" ', '\"j\" '])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abe9xLJqWb4y"
      },
      "outputs": [],
      "source": [
        "silence = np.array(['\"\"', '', '\"\" ','\"sp\" '])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yDxUe4u_r5g"
      },
      "source": [
        "**4.2 Assign Sound Type to New Column**\n",
        "\n",
        "Reading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRKC5mzK_w7i"
      },
      "outputs": [],
      "source": [
        "Type_col = pd.DataFrame(columns=range(1))\n",
        "Type_col.columns = [\"Type\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCho4qVH_IeK"
      },
      "outputs": [],
      "source": [
        "if IDs_reading == []:\n",
        "  pass\n",
        "else:\n",
        "  for i in range(0, len(read_TextGrid_duration)):\n",
        "    if read_TextGrid_duration[\"Sound\"][i] in vowels:\n",
        "      Type_col = Type_col.append({\"Type\":\"vowel\"}, ignore_index=True)\n",
        "    elif read_TextGrid_duration[\"Sound\"][i] in consonants:\n",
        "      Type_col = Type_col.append({\"Type\":\"consonant\"}, ignore_index=True)\n",
        "    elif read_TextGrid_duration[\"Sound\"][i] in silence:\n",
        "      Type_col = Type_col.append({\"Type\":\"silence\"}, ignore_index=True)\n",
        "    else:\n",
        "      print(\"Warning: IPA symbol not in dictionary \", read_TextGrid_duration[\"Sound\"][i])\n",
        "  read_TextGrid_duration = pd.concat([read_TextGrid_duration, Type_col], axis=1)\n",
        "  read_TextGrid_duration = read_TextGrid_duration[[\"ID\", \"Type\", \"Sound\", \"Onset\", \"Offset\", \"Duration\"]]\n",
        "  print(read_TextGrid_duration)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t27CALfGC5lT"
      },
      "source": [
        "**4.2 Assign Sound Type to New Column**\n",
        "\n",
        "Frog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4LzU5eADAFL"
      },
      "outputs": [],
      "source": [
        "Type_col = pd.DataFrame(columns=range(1))\n",
        "Type_col.columns = [\"Type\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xrf6FzZDAAM"
      },
      "outputs": [],
      "source": [
        "if IDs_frog == []:\n",
        "  pass\n",
        "else:\n",
        "  for i in range(0, len(frog_TextGrid_duration)):\n",
        "    if frog_TextGrid_duration[\"Sound\"][i] in vowels:\n",
        "      Type_col = Type_col.append({\"Type\":\"vowel\"}, ignore_index=True)\n",
        "    elif frog_TextGrid_duration[\"Sound\"][i] in consonants:\n",
        "      Type_col = Type_col.append({\"Type\":\"consonant\"}, ignore_index=True)\n",
        "    elif frog_TextGrid_duration[\"Sound\"][i] in silence:\n",
        "      Type_col = Type_col.append({\"Type\":\"silence\"}, ignore_index=True)\n",
        "    else:\n",
        "      print(\"Warning: IPA symbol not in dictionary \", frog_TextGrid_duration[\"Sound\"][i])\n",
        "\n",
        "  frog_TextGrid_duration = pd.concat([frog_TextGrid_duration, Type_col], axis=1)\n",
        "  frog_TextGrid_duration = frog_TextGrid_duration[[\"ID\", \"Type\", \"Sound\", \"Onset\", \"Offset\", \"Duration\"]]\n",
        "  print(frog_TextGrid_duration)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZyvmsVjEQj8"
      },
      "source": [
        "**5. Save Combined Data Files**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFAaLebhEDUf"
      },
      "outputs": [],
      "source": [
        "dir = \"1.CombinedInputFiles\"\n",
        "\n",
        "if os.path.exists(dir) == False:\n",
        "  os.mkdir(dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZnxZsQYEGBd"
      },
      "outputs": [],
      "source": [
        "%cd /content/gdrive/MyDrive/ATAS_Plus/Duration_Metrics/1.CombinedInputFiles/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M02jKfCXEI2d"
      },
      "outputs": [],
      "source": [
        "if IDs_reading == []:\n",
        "  df_read_txt_wide = pd.DataFrame(columns=['ID', 'Onset', 'Offset','Utterance','FluencyStatus'])\n",
        "  read_TextGrid_duration = pd.DataFrame(columns=['ID','Type','Sound','Onset','Offset','Duration'])\n",
        "else:\n",
        "  pass\n",
        "\n",
        "df_read_txt_wide.to_excel(\"read_txt_comb_10_10_23.xlsx\")\n",
        "read_TextGrid_duration.to_excel(\"read_TextGrid_comb_10_10_23.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if IDs_frog ==[]:\n",
        "  df_frog_txt_wide = pd.DataFrame(columns=['ID', 'Onset', 'Offset','Utterance','FluencyStatus'])\n",
        "  frog_TextGrid_duration = pd.DataFrame(columns=['ID','Type','Sound','Onset','Offset','Duration'])\n",
        "else:\n",
        "  pass\n",
        "\n",
        "df_frog_txt_wide.to_excel(\"frog_txt_comb_10_10_23.xlsx\")\n",
        "frog_TextGrid_duration.to_excel(\"frog_TextGrid_comb_10_10_23.xlsx\")"
      ],
      "metadata": {
        "id": "8_9IFVEvWeGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlC_hQLUEMC0"
      },
      "outputs": [],
      "source": [
        "%cd /content/gdrive/MyDrive/RhythmAnalysisPipeline"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}