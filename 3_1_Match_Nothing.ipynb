{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Janina712/RhythmMetrics_Duration/blob/main/3_1_Match_Nothing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0. Imports & Set-Up**"
      ],
      "metadata": {
        "id": "eXWkyVy63-C0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import random as random\n",
        "import os\n",
        "import math\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "uMjIbWqy4Grp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZutGW5p4Gh9",
        "outputId": "5e4df482-d3bb-41c8-f383-377e28b0bb67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/ATAS_Plus/Duration_Metrics/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOruhCny4GYG",
        "outputId": "8f032754-453e-4c93-cbfe-856899b5a679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/ATAS_Plus/Duration_Metrics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reading = pd.read_excel(\"reading_TextGrid_comb_BG_loop.xlsx\")\n",
        "frog = pd.read_excel(\"frog_TextGrid_comb_BG_loop.xlsx\")"
      ],
      "metadata": {
        "id": "Sqs9rtVC4T-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IDs by condition\n",
        "IDs_reading = ['24fa']\n",
        "IDs_frog = ['24fa']"
      ],
      "metadata": {
        "id": "2jt7iYGo4T2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IDs by group\n",
        "pws_IDs = ['24fa']\n",
        "control_IDs = []\n",
        "\n",
        "# combine both groups\n",
        "IDs_col = pd.DataFrame(columns =['ID'])\n",
        "IDs_col['ID'] =['24fa']"
      ],
      "metadata": {
        "id": "SjMGyDMo4TyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Define Functions**"
      ],
      "metadata": {
        "id": "txzzq7Uh0-Ju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.1 Assign Participant Group**"
      ],
      "metadata": {
        "id": "sU_o9HAZ1OTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assign_group(df):\n",
        "  group = pd.DataFrame(index = range(len(df)),columns=[\"Group\"])\n",
        "\n",
        "  for i in range(0,len(df)-1):\n",
        "    if df[\"ID\"][i] in control_IDs:\n",
        "      group[\"Group\"][i] = \"Control\"\n",
        "    else:\n",
        "      group[\"Group\"][i] = \"PWS\"\n",
        "\n",
        "  df_out = pd.concat([ group, df], axis=1)\n",
        "  df_out = df_out[df_out.Type != \"silence\"]\n",
        "  df_out.index = range(len(df_out.index))\n",
        "  df_out.drop(['Unnamed: 0'], axis=1 , inplace = True)\n",
        "  return(df_out)"
      ],
      "metadata": {
        "id": "Kkijbj3b082p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Count Vowels**"
      ],
      "metadata": {
        "id": "3lPm6n--1WJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_vowels(df, condition):\n",
        "  df_vowels = df[df[\"Type\"]  == \"vowel\"]\n",
        "  df_vowels.index = range(len(df_vowels.index))\n",
        "\n",
        "  # reading or interview condition\n",
        "  if condition == \"frog\":\n",
        "    IDs_here = IDs_frog\n",
        "  else:\n",
        "    IDs_here = IDs_reading\n",
        "\n",
        "  syll_col = pd.DataFrame()  ## initialize group-level dataframe\n",
        "  for ID in IDs_here: ## loop over participnts\n",
        "    syll_current_ID = pd.DataFrame()   ## initialize participant-level dataframe\n",
        "    subset_sounds = df[df[\"ID\"] == ID]  # get subset of sound dataframe that corresponds to current participant\n",
        "    subset_sounds.index = range(len(subset_sounds.index)) # reset index\n",
        "    subset_vowels = subset_sounds[subset_sounds[\"Type\"] == \"vowel\"]  # get subset of sound dataframe that corresponds to current participant\n",
        "    subset_vowels.index = range(len(subset_vowels.index)) # reset index\n",
        "    syll = subset_vowels[\"Breath.Group\"].value_counts().sort_index() # count how often a certain Breath group occurs for this participant\n",
        "    syll.index = range(len(syll.index)) # reset index\n",
        "    for a in range (0,len(syll)): # go through all breath groups that this participant produced\n",
        "      syll_current_BG = pd.DataFrame()  ## initialize BG-level dataframe\n",
        "      syll_current_BG = pd.DataFrame(np.repeat(syll.iloc[a], syll.iloc[a], axis=0)) #replicate the sum sum times\n",
        "      syll_current_ID = syll_current_ID.append([syll_current_BG], ignore_index = True) # add BG-level dataframe to participant-level dataframe\n",
        "    syll_col = syll_col.append([syll_current_ID], ignore_index = True) # add participant-level dataframe to group-level dataframe\n",
        "\n",
        "  df_vowels = pd.concat([df_vowels, syll_col], axis=1)\n",
        "  df_vowels.rename(columns = {'Syllables':'Unmached_Vowels'}, inplace = True)\n",
        "  df_vowels.rename(columns = {0:'Syllables'}, inplace = True) # rename new column\n",
        "  pre_df_vowel_avg = df_vowels.groupby(\"Group\").mean()    ########### average counting 13 13 times\n",
        "\n",
        "  return(df_vowels, pre_df_vowel_avg)"
      ],
      "metadata": {
        "id": "shiWCiPF08xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.3 Count Consonants**"
      ],
      "metadata": {
        "id": "5wWRnPtR1fGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_consonants(df, condition):\n",
        "  df_consonants = df[df[\"Type\"]  == \"consonant\"]\n",
        "  df_consonants.index = range(len(df_consonants.index))\n",
        "\n",
        "  # reading or interview condition\n",
        "  if condition == \"frog\":\n",
        "    IDs_here = IDs_frog\n",
        "  else:\n",
        "    IDs_here = IDs_reading\n",
        "\n",
        "  con_col = pd.DataFrame()  ## initialize group-level dataframe\n",
        "  for ID in IDs_here: ## loop over participnts\n",
        "    con_current_ID = pd.DataFrame()   ## initialize participant-level dataframe\n",
        "    subset_sounds = df[df[\"ID\"] == ID]  # get subset of sound dataframe that corresponds to current participant\n",
        "    subset_sounds.index = range(len(subset_sounds.index)) # reset index\n",
        "    subset_cons = subset_sounds[subset_sounds[\"Type\"] == \"consonant\"]  # get subset of sound dataframe that corresponds to current participant\n",
        "    subset_cons.index = range(len(subset_cons.index)) # reset index\n",
        "    con = subset_cons[\"Breath.Group\"].value_counts().sort_index() # count how often a certain Breath group occurs for this participant\n",
        "    con.index = range(len(con.index)) # reset index\n",
        "    for a in range (0,len(con)): # go through all breath groups that this participant produced\n",
        "      con_current_BG = pd.DataFrame()  ## initialize BG-level dataframe\n",
        "      con_current_BG = pd.DataFrame(np.repeat(con.iloc[a], con.iloc[a], axis=0)) #replicate the sum sum times\n",
        "      con_current_ID = con_current_ID.append([con_current_BG], ignore_index = True) # add BG-level dataframe to participant-level dataframe\n",
        "    con_col = con_col.append([con_current_ID], ignore_index = True) # add participant-level dataframe to group-level dataframe\n",
        "\n",
        "  df_consonants = pd.concat([df_consonants, con_col], axis=1)\n",
        "  df_consonants.rename(columns = {'Consonants':'Unmatched_Cons'}, inplace = True)\n",
        "  df_consonants.rename(columns = {0:'Consonants'}, inplace = True) # rename new column\n",
        "  pre_df_consonant_avg = df_consonants.groupby(\"Group\").mean()    ########### average counting 13 13 times\n",
        "\n",
        "  return(df_consonants, pre_df_consonant_avg)"
      ],
      "metadata": {
        "id": "wdvBNybc08tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.4. Average Vowel Count Per Participant**"
      ],
      "metadata": {
        "id": "XasnT_fm1mEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def participant_vowel_avg(df, condition):\n",
        "  group_col = pd.DataFrame(index = range(len(IDs_col)),columns=[\"Group\"])\n",
        "  for i in range(0,len(group_col)):\n",
        "    if df[\"ID\"][i] in control_IDs:\n",
        "      group_col[\"Group\"][i] = \"Control\"\n",
        "    else:\n",
        "      group_col[\"Group\"][i] = \"PWS\"\n",
        "\n",
        "    # reading or interview condition\n",
        "  if condition == \"frog\":\n",
        "    IDs_here = IDs_frog\n",
        "  else:\n",
        "    IDs_here = IDs_reading\n",
        "\n",
        "  n = -1\n",
        "  avg_col = pd.DataFrame(index = range(len(IDs_col)),columns=[\"Syllables\"])   # Syllables\n",
        "  for ID in IDs_here: ## loop over participnts\n",
        "    n = n + 1\n",
        "    subset_BGs = df[df[\"ID\"] == ID]  # get subset of sound dataframe that corresponds to current participant\n",
        "    subset_BGs.index = range(len(subset_BGs.index)) # reset index\n",
        "    BG_avg = subset_BGs.groupby(\"Breath.Group\").mean()\n",
        "    subj_avg = BG_avg[\"Syllables\"].mean()\n",
        "    avg_col[\"Syllables\"][n] = subj_avg\n",
        "\n",
        "  df_participant_vowel_avg = pd.concat([group_col, IDs_col, avg_col], axis=1)\n",
        "\n",
        "  return(df_participant_vowel_avg)"
      ],
      "metadata": {
        "id": "Bn_YYGLT08rU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.5. Average Consonant Count Per Participant**"
      ],
      "metadata": {
        "id": "Y0DDITIo1t4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def participant_consonant_avg(df, condition):\n",
        "  group_col = pd.DataFrame(index = range(len(IDs_col)),columns=[\"Group\"])\n",
        "  for i in range(0,len(group_col)):\n",
        "    if df[\"ID\"][i] in control_IDs:\n",
        "      group_col[\"Group\"][i] = \"Control\"\n",
        "    else:\n",
        "      group_col[\"Group\"][i] = \"PWS\"\n",
        "\n",
        "  # reading or interview condition\n",
        "  if condition == \"frog\":\n",
        "    IDs_here = IDs_frog\n",
        "  else:\n",
        "    IDs_here = IDs_reading\n",
        "\n",
        "  n = -1\n",
        "  avg_col = pd.DataFrame(index = range(len(IDs_col)),columns=[\"Consonants\"])\n",
        "  for ID in IDs_here: ## loop over participnts\n",
        "    n = n + 1\n",
        "    subset_BGs = df[df[\"ID\"] == ID]  # get subset of sound dataframe that corresponds to current participant\n",
        "    subset_BGs.index = range(len(subset_BGs.index)) # reset index\n",
        "    BG_avg = subset_BGs.groupby(\"Breath.Group\").mean()\n",
        "    subj_avg = BG_avg[\"Consonants\"].mean()\n",
        "    avg_col[\"Consonants\"][n] = subj_avg\n",
        "\n",
        "  df_participant_cons_avg = pd.concat([group_col, IDs_col, avg_col], axis=1)\n",
        "\n",
        "  return(df_participant_cons_avg)"
      ],
      "metadata": {
        "id": "TMUFHk8508p4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.6. Compare Consonant and Vowel Counts Across Groups**"
      ],
      "metadata": {
        "id": "MXe8_1QS15a9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_groups(df_vowels, df_consonants):\n",
        "  control_v = (df_vowels.groupby('ID').mean()[\"Syllables\"][len(pws_IDs):(len(pws_IDs)+len(control_IDs))]).mean()\n",
        "  pws_v = (df_vowels.groupby('ID').mean()[\"Syllables\"][0:len(pws_IDs)]).mean()\n",
        "  difference_v = control_v - pws_v\n",
        "\n",
        "  control_c = (df_consonants.groupby('ID').mean()[\"Consonants\"][len(pws_IDs):(len(pws_IDs)+len(control_IDs))]).mean()\n",
        "  pws_c = (df_consonants.groupby('ID').mean()[\"Consonants\"][0:len(pws_IDs)]).mean()\n",
        "  difference_c = control_c - pws_c\n",
        "\n",
        "  string1 = (f\"PWS produced on average {round(pws_v,2)} syllables per utterance, while control participants produced {round(control_v,2)} syllables on average.\")\n",
        "  string2 = (f\"This means that on average control participants produced {round(difference_v,2)} syllables more per utterance.\")\n",
        "  string3 = (f\"\\nPWS produced on average {round(pws_c,2)} consonants per utterance, while control participants produced {round(control_c,2)} consonants on average.\")\n",
        "  string4 = (f\"This means that on average control participants produced {round(difference_c,2)} consonants more per utterance.\")\n",
        "\n",
        "  return(string1, string2, string3, string4, pws_v, pws_c, difference_v, difference_c)"
      ],
      "metadata": {
        "id": "h7VfgLf108ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Prepare DataFrame**"
      ],
      "metadata": {
        "id": "gwu0egTK0jRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add new column to dataframe that denotes participant's group membership\n",
        "frog = frog.dropna()\n",
        "frog = assign_group(frog)\n",
        "reading = reading.dropna()\n",
        "reading = assign_group(reading)"
      ],
      "metadata": {
        "id": "o8rEcblUzyUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# account for case differences in annotation\n",
        "for i in range (0, len(frog)):\n",
        "  frog[\"FluencyStatus\"][i] = frog[\"FluencyStatus\"][i].lower().strip()\n",
        "for i in range (0, len(reading)):\n",
        "  reading[\"FluencyStatus\"][i] = reading[\"FluencyStatus\"][i].lower().strip()"
      ],
      "metadata": {
        "id": "MTufoPo21YFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# exclude disfluent utterances from further analysis\n",
        "frog_fluent = frog[frog[\"FluencyStatus\"] == \"fluent\"]\n",
        "frog_fluent.index = range(len(frog_fluent.index))\n",
        "reading_fluent = reading[reading[\"FluencyStatus\"] == \"fluent\"]\n",
        "reading_fluent.index = range(len(reading_fluent.index))"
      ],
      "metadata": {
        "id": "qptLbpxDzyE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count vowels per utterance\n",
        "[frog_vowels_fluent, pre_frog_vowel_avg_fluent]  = count_vowels(frog_fluent, \"frog\")\n",
        "[reading_vowels_fluent, pre_reading_vowel_avg_fluent] = count_vowels(reading_fluent, \"reading\")"
      ],
      "metadata": {
        "id": "L16byk0zzx0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count consonants per utterance\n",
        "[frog_consonants_fluent, pre_frog_consonant_avg_fluent]  = count_consonants(frog_fluent,'frog')\n",
        "[reading_consonants_fluent, pre_reading_consonants_avg_fluent] = count_consonants(reading_fluent,'reading')"
      ],
      "metadata": {
        "id": "dxJsinju0FTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#average # vowels per breath group for each participant\n",
        "frog_participant_vowel_avg_fluent = participant_vowel_avg(frog_vowels_fluent,'frog')\n",
        "reading_participant_vowel_avg_fluent = participant_vowel_avg(reading_vowels_fluent,'reading')"
      ],
      "metadata": {
        "id": "D0_01a0P0FPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#average # consonants per breath group for each participant\n",
        "frog_participant_cons_avg_fluent = participant_consonant_avg(frog_consonants_fluent,'frog')\n",
        "reading_participant_cons_avg_fluent = participant_consonant_avg(reading_consonants_fluent,'reading')"
      ],
      "metadata": {
        "id": "QQwHth1D0FMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compare group averages of number of vowels per utterance and number of consonants per utterance\n",
        "# frog\n",
        "string1, string2, string3, string4, pws_v_frog_fluent, pws_c_frog_fluent, difference_v_frog_fluent, difference_c_frog_fluent = compare_groups(frog_participant_vowel_avg_fluent, frog_participant_cons_avg_fluent)\n",
        "\n",
        "print(string1)\n",
        "print(string2)\n",
        "print(string3)\n",
        "print(string4)"
      ],
      "metadata": {
        "id": "iYsf1sC_0FJw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2fb6d7f-d8a1-43ff-8a0d-19137a8371d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PWS produced on average 8.91 syllables per utterance, while control participants produced nan syllables on average.\n",
            "This means that on average control participants produced nan syllables more per utterance.\n",
            "\n",
            "PWS produced on average 13.97 consonants per utterance, while control participants produced nan consonants on average.\n",
            "This means that on average control participants produced nan consonants more per utterance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compare group averages of number of vowels per utterance and number of consonants per utterance\n",
        "# reading\n",
        "string5, string6, string7, string8, pws_v_read_fluent, pws_c_read_fluent, difference_v_read_fluent, difference_c_read_fluent  = compare_groups(reading_participant_vowel_avg_fluent, reading_participant_cons_avg_fluent)\n",
        "\n",
        "print(string5)\n",
        "print(string6)\n",
        "print(string7)\n",
        "print(string8)"
      ],
      "metadata": {
        "id": "Dns3yQoN0FCz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "136cf5fc-ac1a-4cd5-b25c-5a646d4923cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PWS produced on average 6.5 syllables per utterance, while control participants produced nan syllables on average.\n",
            "This means that on average control participants produced nan syllables more per utterance.\n",
            "\n",
            "PWS produced on average 9.5 consonants per utterance, while control participants produced nan consonants on average.\n",
            "This means that on average control participants produced nan consonants more per utterance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Create Dataframe**"
      ],
      "metadata": {
        "id": "npo2WXXG0dcS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3xAO28vywqQ"
      },
      "outputs": [],
      "source": [
        "reading_vowels_matched_fluent = reading_vowels_fluent\n",
        "frog_vowels_matched_fluent = frog_vowels_fluent\n",
        "reading_consonants_matched_fluent = reading_consonants_fluent\n",
        "frog_consonants_matched_fluent = frog_consonants_fluent"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if IDs_reading == []:\n",
        "  reading_vowels_matched_fluent['Syllables'] = []\n",
        "  reading_consonants_matched_fluent['Consonants'] = []\n",
        "if IDs_frog == []:\n",
        "  frog_vowels_matched_fluent['Syllables'] = []\n",
        "  frog_consonants_matched_fluent['Consonants'] = []"
      ],
      "metadata": {
        "id": "-twvYb1aBfr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Save**"
      ],
      "metadata": {
        "id": "YGzDO5oU4pc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/ATAS_Plus/Duration_Metrics"
      ],
      "metadata": {
        "id": "9uTjuan34sWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir = \"3.MLU_Matched\"\n",
        "\n",
        "if os.path.exists(dir) == False:\n",
        "  os.mkdir(dir)"
      ],
      "metadata": {
        "id": "aWq4ro_l4sMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/ATAS_Plus/Duration_Metrics/3.MLU_Matched/"
      ],
      "metadata": {
        "id": "48S0hJOM4r_q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e0736ca-8828-4057-90f0-45e062eb190a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/ATAS_Plus/Duration_Metrics/3.MLU_Matched\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# export\n",
        "reading_vowels_matched_fluent.to_excel(\"matchedVowels_reading_FLUENT.xlsx\")\n",
        "reading_consonants_matched_fluent.to_excel(\"matchedConsonants_reading_FLUENT.xlsx\")\n",
        "frog_vowels_matched_fluent.to_excel(\"matchedVowels_frog_FLUENT.xlsx\")\n",
        "frog_consonants_matched_fluent.to_excel(\"matchedConsonants_frog_FLUENT.xlsx\")"
      ],
      "metadata": {
        "id": "PRAnMina4r2w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}